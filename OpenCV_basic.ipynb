{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 현재경로 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kwang\\iCloudDrive\\Python\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 카메라에서 이미지 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "capture = cv2.VideoCapture(0) # 노트북의 내장 카메라 장치번호가 '0'\n",
    "capture.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "while True:\n",
    "    ret, frame = capture.read()\n",
    "    print(ret, frame)\n",
    "    cv2.imshow(\"VideoFrame\", frame)\n",
    "    if cv2.waitKey(1) > 0 : break\n",
    "        \n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread(\"Image/lunar.jpg\", cv2.IMREAD_ANYCOLOR)\n",
    "cv2.imshow(\"Moon\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width, channel = image.shape\n",
    "\n",
    "print(height, width, channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "동영상 파일에서 이미지를 얻어와 프레임을 재생할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "capture = cv2.VideoCapture(\"Image/star.mp4\")\n",
    "\n",
    "while True:\n",
    "    if(capture.get(cv2.CAP_PROP_POS_FRAMES) == capture.get(cv2.CAP_PROP_FRAME_COUNT)):\n",
    "        capture.open(\"image/star.mp4\")\n",
    "    \n",
    "    ret, frame = capture.read()\n",
    "    cv2.imshow(\"VideoFrame\", frame)\n",
    "    \n",
    "    if cv2.waitKey(33) > 0: break\n",
    "        \n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "line3: 해당 경로의 star.mp4 동영상 파일에서 프레임을 받아온다\n",
    "\n",
    "line6: cv2.CAP_PROP_POS_FRAMES 는 현재 프레임 개수<br />\n",
    "       cv2.CAP_PROP_FRAME_COUNT 는 총 프레임 개수\n",
    "       \n",
    "line7: 프레임 개수가 같을 경우(마지막 프레임), capture.open(경로) 를 이용하여 다시 동영상 파일을 불러온다.\n",
    "\n",
    "line12: cv2.waitkey(time)을 이용하여 33ms마다 프레임을 재생합니다.\n",
    "\n",
    "어떤 키라도 누를 경우, break하여 while문을 종료합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VideoCapture 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "capture.get(속성) : VideoCapture의 속성을 반환합니다.\n",
    "\n",
    "capture.grab() : Frame의 호출 성공 유/무를 반환합니다.\n",
    "\n",
    "capture.isOpened() : VideoCapture의 성공 유/무를 반환합니다.\n",
    "\n",
    "capture.open(카메라 장치 번호 또는 경로) : 카메라나 동영상 파일을 엽니다.\n",
    "\n",
    "capture.release() : VideoCapture의 장치를 닫고 메모리를 해제합니다.\n",
    "\n",
    "capture.retrieve() : VideoCapture의 프레임과 플래그를 반환합니다.\n",
    "\n",
    "capture.set(속성, 값) : VideoCapture의 속성의 값을 설정합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VideoCapture 속성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![VideoCapture%20%EC%86%8D%EC%84%B1.PNG](attachment:VideoCapture%20%EC%86%8D%EC%84%B1.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 대칭 (Flip, Symmetry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "영상이나 이미지를 대칭시켜 띄울 수 있습니다.\n",
    "\n",
    "\n",
    "상하 또는 좌우 방향으로 대칭할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "src = cv2.imread(\"Image/glass.jpg\", cv2.IMREAD_COLOR)\n",
    "dst = cv2.flip(src, 0)\n",
    "\n",
    "# cv2.imshow(\"src\", src)\n",
    "cv2.imshow(\"dst\", dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv2.flip(원본 이미지, 대칭 방법)을 의미합니다.\n",
    "\n",
    "대칭 방법은 상수를 입력하여 대칭시킬 수 있습니다.\n",
    "\n",
    "0일 경우, 상하방향으로 대칭합니다.\n",
    "\n",
    "1일 경우, 좌우방향으로 대칭합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 회전 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "src = cv2.imread(\"image/ara.jpg\", cv2.IMREAD_COLOR)\n",
    "\n",
    "height, width, channel = src.shape\n",
    "matrix = cv2.getRotationMatrix2D((width/2, height/2), 90, 1)\n",
    "# print(matrix)\n",
    "dst = cv2.warpAffine(src, matrix, (width, height))\n",
    "\n",
    "cv2.imshow(\"src\", src)   # cv2.imshow(윈도우 창의 Title, image)\n",
    "cv2.imshow(\"dst\", dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "line5: 해당 이미지의 높이, 너비, 채널 값 저장\n",
    "\n",
    "line6: cv2.getRotationMatrix2D((중심점 X좌표, 중심점 Y좌표), 각도, 스케일) 라는 배열을 matrix라는 이름의 변수로 저장\n",
    "\n",
    "(중심점 x좌표, 중심점 y좌표) <<- 회전할 기준점\n",
    "\n",
    "스케일: 이미지의 확대 비율 설정\n",
    "\n",
    "line8: cv2.warpAffine(원본 이미지, 배열, (결과 이미지 너비, 결과 이미지 높이))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 피라미드(확대, 축소) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 피라미드 (Image Pyramid)란 이미지의 크기를 변화시켜 원하는 단계까지 샘플링하는 작업입니다. 영상이나 이미지를 확대, 축소시켜 띄울 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "src = cv2.imread(\"Image/fruits.jpg\", cv2.IMREAD_COLOR)\n",
    "\n",
    "height, width, channel = src.shape\n",
    "\n",
    "# cv2.pyrUp(원본이미지, 결과이미지 크기, 픽셀 외삽법)\n",
    "dst = cv2.pyrUp(src, dstsize=(width*2, height*2), borderType=cv2.BORDER_DEFAULT)\n",
    "\n",
    "# 원본이미지를 1/4배로 축소\n",
    "dst2 = cv2.pyrDown(src)\n",
    "\n",
    "cv2.imshow(\"src\", src)\n",
    "cv2.imshow(\"dst\", dst)\n",
    "cv2.imshow(\"dst2\", dst2)\n",
    "cv2.waitKey(0)  # 아무 키를 누를 때까지 기다린다\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 크기 조절 (Resize) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280, 1920, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "src = cv2.imread(\"image/champagne.jpg\", cv2.IMREAD_COLOR)\n",
    "\n",
    "src.shape\n",
    "\n",
    "# dst = cv2.resize(src, dsize=(640, 480), interpolation=cv2.INTER_AREA)\n",
    "# dst2 = cv2.resize(src, dsize=(0, 0), fx=0.3, fy=0.7, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "# # cv2.imshow(\"src\", src)\n",
    "# cv2.imshow(\"dst\", dst)\n",
    "# cv2.imshow(\"dst2\", dst2)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### line5\n",
    "\n",
    "cv2.resize(원본 이미지, 결과 이미지 크기, 보간법)\n",
    "\n",
    "보간법은 이미지의 크기를 변경하는 경우, 변형된 이미지의 픽셀은 추정해서 값을 할당해야합니다.\n",
    "\n",
    "보간법을 이용하여 픽셀들의 값을 할당합니다.\n",
    "\n",
    "\n",
    "### line6\n",
    "cv2.resize(원본 이미지, dsize=(0, 0), 가로비, 세로비, 보간법)\n",
    "\n",
    "결과 이미지 크기가 (0, 0)으로 크기를 설정하지 않은 경우<br />\n",
    "fx가 0.3인 경우, 원본 이미지 너비의 0.3배로 변경됩니다.<br />\n",
    "fy가 0.7인 경우, 원본 이미지 높이의 0.7배로 변경됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)\n",
    "\n",
    "기본적으로 쌍 선형 보간법이 가장 많이 사용됩니다.\n",
    "\n",
    "이미지를 확대하는 경우, 바이큐빅 보간법이나 쌍 선형 보간법을 가장 많이 사용합니다.\n",
    "\n",
    "이미지를 축소하는 경우, 영역 보간법을 가장 많이 사용합니다.\n",
    "\n",
    "영역 보간법에서 이미지를 확대하는 경우, 이웃 보간법과 비슷한 결과를 반환합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 자르기 (Slice) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "src = cv2.imread(\"image/pawns.jpg\", cv2.IMREAD_COLOR)\n",
    "# src.shape\n",
    "\n",
    "dst = src.copy() # 원본에 영향을 미치기 때문에 copy 하여 자른다\n",
    "dst = src[100:600, 200:700] # [높이(행), 너비(열)]\n",
    "\n",
    "cv2.imshow(\"src\", src)\n",
    "cv2.imshow(\"dst\", dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "src = cv2.imread(\"image/pawns.jpg\", cv2.IMREAD_COLOR)\n",
    "\n",
    "dst = src.copy()\n",
    "roi = src[100:600, 200:700]\n",
    "dst[0:500, 0:500] = roi\n",
    "\n",
    "cv2.imshow(\"src\", src)\n",
    "cv2.imshow(\"dst\", dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "src = cv2.imread(\"image/crow.jpg\", cv2.IMREAD_COLOR)\n",
    "\n",
    "dst = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY) # GRAY 에 아래 색상 공간 코드를 참고하여 원하는 색상 공간 코드를 넣는다\n",
    "\n",
    "cv2.imshow(\"src\", src)\n",
    "cv2.imshow(\"dst\", dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 색상 공간 코드\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 역상 (Reverse Image)\n",
    "\n",
    "반전된 색상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "src = cv2.imread(\"image/whitebutterfly.jpg\", cv2.IMREAD_COLOR)\n",
    "src2 = cv2.resize(src, dsize=(640, 480), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "dst = cv2.bitwise_not(src2)\n",
    "\n",
    "cv2.imshow(\"src2\", src2)\n",
    "cv2.imshow(\"dst\", dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이진화 (Binary)\n",
    "\n",
    "영상이나 이미지를 어느 지점을 기준으로 흑색 또는 흰색의 색상으로 변환하기 위해서 사용합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "src = cv2.imread(\"image/geese.jpg\", cv2.IMREAD_COLOR)\n",
    "\n",
    "# 이진화를 하기 위해서 그레이 스케일로 변환\n",
    "gray = cv2.cvtColor(src, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# cv2.threshold(그레이스케일 이미지, 임계값, 최댓값, 임계값 종류)\n",
    "ret, dst = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "dst2 = cv2.resize(dst, dsize=(640, 480), interpolation=cv2.INTER_AREA)\n",
    "cv2.imshow(\"dst2\", dst2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)\n",
    "\n",
    "임계값은 이미지의 흑백을 나눌 기준값을 의미합니다. 100으로 설정할 경우, 100보다 이하면 0으로, 100보다 이상이면 최댓값으로 변경합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 흐림 효과 (Blur) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "src = cv2.imread(\"image/plums.jpg\", cv2.IMREAD_COLOR)\n",
    "resized_src = cv2.resize(src, dsize=(640, 480))\n",
    "\n",
    "# cv2.blur(원본 이미지, (커널 x크기, 커널 y크기), 앵커 포인트, 픽셀 외삽법)\n",
    "dst = cv2.blur(resized_src, (9, 9), anchor=(-1, -1), borderType=cv2.BORDER_DEFAULT)\n",
    "\n",
    "\n",
    "cv2.imshow(\"src\", resized_src)\n",
    "cv2.imshow(\"dst\", dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "커널 크기는 이미지에 흐림 효과를 적용할 크기를 설정합니다. 크기가 클수록 더 많이 흐려집니다.\n",
    "\n",
    "앵커 포인트는 커널에서의 중심점을 의미합니다. (-1, -1)로 사용할 경우, 자동적으로 커널의 중심점으로 할당합니다.\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 가장자리 검출 (Edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "src = cv2.imread(\"image/wheat.jpg\", cv2.IMREAD_COLOR)\n",
    "src2 = cv2.resize(src, dsize=(550, 380))\n",
    "\n",
    "gray = cv2.cvtColor(src2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# cv2.Canny(원본이미지, 임계값1, 임계값2, 커널크기, L2그라디언트)\n",
    "canny = cv2.Canny(src2, 100, 255)\n",
    "\n",
    "# cv2.Sobel(그레이스케일 이미지, 정밀도, x방향 미분, y방향 미분, 커널, 배율, 델타, 픽셀외삽법)\n",
    "sobel = cv2.Sobel(gray, cv2.CV_8U, 1, 0, 3)\n",
    "\n",
    "# cv2.Laplacian(그레이스케일 이미지, 정밀도, 커널, 배율, 델타, 픽셀 외삽법)\n",
    "laplacian = cv2.Laplacian(gray, cv2.CV_8U, ksize=3)\n",
    "\n",
    "cv2.imshow(\"src2\", src2)\n",
    "cv2.imshow(\"canny\", canny)\n",
    "cv2.imshow(\"sobel\", sobel)\n",
    "cv2.imshow(\"laplacian\", laplacian)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\*<big>line8</big><br /><br/>\n",
    "임계값1: 임계값1 이하에 포함된 가장자리는 가장자리에서 제외합니다. <br />\n",
    "임계값2: 임계값2 이상에 포함된 가장자리는 가장자리로 간주합니다.<br />\n",
    "커널 크기: Sobel 마스크의 Aperture Size를 의미합니다. 포함하지 않을 경우, 자동으로 할당됩니다. <br />\n",
    "L2그라디언트: L2방식의 사용 유/무를 설정합니다. 사용하지 않을 경우, 자동적으로 L1그라디언트 방식을 사용합니다.<br />\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\*<big>line11</big><br /><br />\n",
    "\n",
    "정밀도는 결과 이미지의 이미지 정밀도를 의미합니다. 정밀도에 따라 결과물이 달라질 수 있습니다.\n",
    "\n",
    "x 방향 미분은 이미지에서 x 방향으로 미분할 값을 설정합니다.\n",
    "\n",
    "y 방향 미분은 이미지에서 y 방향으로 미분할 값을 설정합니다.\n",
    "\n",
    "커널은 소벨 커널의 크기를 설정합니다. 1, 3, 5, 7의 값을 사용합니다.\n",
    "\n",
    "배율은 계산된 미분 값에 대한 배율값입니다.\n",
    "\n",
    "델타는 계산전 미분 값에 대한 추가값입니다.\n",
    "\n",
    "픽셀 외삽법은 이미지를 가장자리 처리할 경우, 영역 밖의 픽셀은 추정해서 값을 할당해야합니다.\n",
    "\n",
    "*Tip : x방향 미분 값과 y방향의 미분 값의 합이 1 이상이여야 하며 각각의 값은 0보다 커야합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HSV (Hue, Saturation, Value)\n",
    "영상이나 이미지의 색상을 검출 하기 위해 사용합니다. 채널을 Hue, Saturation, Value로 분리하여 변환할 수 있습니다.\n",
    "\n",
    "\n",
    "* 색상 (Hue) : 색의 질입니다. 빨강, 노랑, 파랑이라고 하는 표현으로 나타내는 성질입니다.\n",
    "* 채도 (Saturation) : 색의 선명도입니다. 아무것도 섞지 않아 맑고 깨끗하며 원색에 가까운 것을 채도가 높다고 표현합니다.\n",
    "* 명도 (Value) : 색의 밝기입니다. 명도가 높을수록 백색에, 명도가 낮을수록 흑색에 가까워집니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Code (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "src = cv2.imread(\"image/tomato.jpg\", cv2.IMREAD_COLOR)\n",
    "src2 = cv2.resize(src, dsize=(520, 280))\n",
    "\n",
    "# convert color from BGR to HSV\n",
    "hsv = cv2.cvtColor(src2, cv2.COLOR_BGR2HSV) \n",
    "\n",
    "# 각 속성으로 채널을 분리\n",
    "h, s, v = cv2.split(hsv)\n",
    "\n",
    "cv2.imshow(\"src\", src2)\n",
    "cv2.imshow(\"h\", h)\n",
    "cv2.imshow(\"s\", s)\n",
    "cv2.imshow(\"v\", v)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Code (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "src = cv2.imread(\"image/tomato.jpg\", cv2.IMREAD_COLOR)\n",
    "src2 = cv2.resize(src, dsize=(520, 280))\n",
    "hsv = cv2.cvtColor(src2, cv2.COLOR_BGR2HSV)\n",
    "h, s, v = cv2.split(hsv)\n",
    "\n",
    "cv2.imshow(\"h1\", h)\n",
    "cv2.imshow(\"s\", s)\n",
    "cv2.imshow(\"v\", v)\n",
    "\n",
    "# cv2.inRange(단일 채널 이미지, 최솟값, 최댓값)\n",
    "h = cv2.inRange(h, 8, 20)\n",
    "cv2.imshow(\"h2\", h)\n",
    "\n",
    "orange = cv2.bitwise_and(hsv, hsv, mask = h)\n",
    "\n",
    "cv2. imshow(\"orange1\", orange)\n",
    "\n",
    "orange = cv2.cvtColor(orange, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "cv2.imshow(\"hsv\", hsv)\n",
    "cv2.imshow(\"src\", src2)\n",
    "cv2.imshow(\"orange2\", orange)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hue의 범위를 조정하여 특정 색상만 출력할 수 있습니다.\n",
    "\n",
    "cv2.inRange(단일 채널 이미지, 최솟값, 최댓값)을 이용하여 범위를 설정합니다.\n",
    "\n",
    "주황색은 약 8~20 범위를 갖습니다.\n",
    "\n",
    "이 후, 해당 마스크를 이미지 위에 덧씌워 해당 부분만 출력합니다.\n",
    "\n",
    "cv2.bitwise_and(원본, 원본, mask = 단일 채널 이미지)를 이용하여 마스크만 덧씌웁니다.\n",
    "\n",
    "이 후, 다시 HSV 속성에서 BGR 속성으로 변경합니다.\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "\n",
    "* 색상 (Hue) : 0 ~ 180의 값을 지닙니다.\n",
    "* 채도 (Saturation) : 0 ~ 255의 값을 지닙니다.\n",
    "* 명도 (Value) : 0 ~ 255의 값을 지닙니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 채널 범위 병합 (addWeighted)\n",
    "\n",
    "영상이나 이미지의 색상을 검출할 때, cv2.inRange()의 영역이 한정되어 색상을 설정하는 부분이 한정되어 있습니다. 이 때 특정 범위들을 병합할 때 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "src = cv2.imread(\"image/tomato.jpg\", cv2.IMREAD_COLOR)\n",
    "src2 = cv2.resize(src, dsize=(520, 280))\n",
    "hsv = cv2.cvtColor(src2, cv2.COLOR_BGR2HSV)\n",
    "h, s, v = cv2.split(hsv)\n",
    "\n",
    "lower_red = cv2.inRange(hsv, (0, 100, 100), (5, 255, 255))\n",
    "upper_red = cv2.inRange(hsv, (170, 100, 100), (180, 255, 255))\n",
    "added_red = cv2.addWeighted(lower_red, 1.0, upper_red, 1.0, 0.0)\n",
    "\n",
    "red = cv2.bitwise_and(hsv, hsv, mask = added_red)\n",
    "red = cv2.cvtColor(red, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "cv2.imshow(\"src\", src2)\n",
    "cv2.imshow(\"red\", red)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
